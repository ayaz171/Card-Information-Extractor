{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "card_extract.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "30vHD8e-sgNH",
        "outputId": "0a1f0a89-ece2-4eb1-9cd7-ab4238e98ee9"
      },
      "source": [
        "# Importing the necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import dlib\n",
        "import matplotlib.patches as mpatches\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import cv2\n",
        "!pip install easyocr\n",
        "import easyocr\n",
        "import csv\n",
        "import spacy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.4.1-py3-none-any.whl (63.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.6 MB 57 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.10.0+cu111)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.18.3)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.11.1+cu111)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.4.1)\n",
            "Requirement already satisfied: Pillow<8.3.0 in /usr/local/lib/python3.7/dist-packages (from easyocr) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from easyocr) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.19.5)\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->easyocr) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.11.0)\n",
            "Installing collected packages: python-bidi, opencv-python-headless, easyocr\n",
            "Successfully installed easyocr-1.4.1 opencv-python-headless-4.5.4.60 python-bidi-0.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAXRAzhVsqCj"
      },
      "source": [
        "# Using DLIB for face detection\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "image = io.imread(\"/content/IDjpg.jpg\")\n",
        "dets = detector(image, 2)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "-6wySoqJtE7z",
        "outputId": "44e354fe-03d5-48d7-ddeb-79982c467170"
      },
      "source": [
        "## Visualize the recognized image\n",
        "plt.figure()\n",
        "ax = plt.subplot(111)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "for i, face in enumerate(dets):\n",
        "    # Annotate faces in pictures and display\n",
        "    left = face.left()\n",
        "    top = face.top()\n",
        "    right = face.right()\n",
        "    bottom = face.bottom()\n",
        "    rect = mpatches.Rectangle((left,bottom), right - left, top - bottom,\n",
        "                              fill=False, edgecolor='green', linewidth=1)\n",
        "    ax.add_patch(rect)\n",
        "plt.show()\n",
        "\n",
        "predictor = dlib.shape_predictor(\"/content/shape_predictor_5_face_landmarks.dat\")\n",
        "detected_landmarks = predictor(image, dets[0]).parts()\n",
        "landmarks = np.array([[p.x, p.y] for p in detected_landmarks])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH5I2jWStw1r"
      },
      "source": [
        "## Calculate the tilt angle of the eyes,Counterclockwise angle\n",
        "def twopointcor(point1,point2):\n",
        "    \"\"\"point1 = (x1,y1),point2 = (x2,y2)\"\"\"\n",
        "    deltxy = point2 - point1\n",
        "    corner = np.arctan(deltxy[1] / deltxy[0]) * 180 / np.pi\n",
        "    return corner"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUlfalRkt2ii"
      },
      "source": [
        "## Calculate average from multiple angles\n",
        "corner10 =  twopointcor(landmarks[1,:],landmarks[0,:])\n",
        "corner23 =  twopointcor(landmarks[3,:],landmarks[2,:])\n",
        "corner20 =  twopointcor(landmarks[2,:],landmarks[0,:])\n",
        "corner = np.mean([corner10,corner23,corner20])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDaCoeUyt5aE"
      },
      "source": [
        "## Calculate the tilt angle of the image ID card\n",
        "def IDcorner(landmarks):\n",
        "    \"\"\"landmarks:Detected faces5Feature points\n",
        "              After testing using the first0And2The calculation angle of two feature points is more appropriate\n",
        "    \"\"\"\n",
        "    corner20 =  twopointcor(landmarks[2,:],landmarks[0,:])\n",
        "    corner = np.mean([corner20])\n",
        "    return corner\n",
        "corner = IDcorner(landmarks)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXmEzB86t8TA"
      },
      "source": [
        "## Tilt the photo\n",
        "def rotateIdcard(image):\n",
        "    \"image :Image to be processed\"\n",
        "    ## used dlib.get_frontal_face_detector for Face recognition\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    dets = detector(image, 2)\n",
        "    ## Detect where the eyes of the face are\n",
        "    predictor = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")\n",
        "    detected_landmarks = predictor(image, dets[0]).parts()\n",
        "    landmarks = np.array([[p.x, p.y] for p in detected_landmarks])\n",
        "    corner = IDcorner(landmarks)\n",
        "    ## Rotated image\n",
        "    image2 = transform.rotate(image,corner,clip=False)\n",
        "    image2 = np.uint8(image2*255)\n",
        "    ## Face position after rotation\n",
        "    det = detector(image2, 2)\n",
        "    return image2,det\n",
        "\n",
        "\n",
        "image2,dets = rotateIdcard(image)\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB) # Converting image to RGB format"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBg_KDSWuAIK",
        "outputId": "edc4a8f5-204a-4b8f-de94-f51a88c4f592"
      },
      "source": [
        "# Saving the image\n",
        "cv2.imwrite('2 rotated_img.jpg',image2)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEyeJogXuL0C"
      },
      "source": [
        "# Taking the previously saved image as input to extract face photo\n",
        "input_image_path = '2 rotated_img.jpg'\n",
        "img = cv2.imread(input_image_path)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "invGamma = 1.0 / 0.3\n",
        "table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Xyl8n1usuz"
      },
      "source": [
        "# apply gamma correction using the lookup table\n",
        "gray = cv2.LUT(gray, table)\n",
        "ret, thresh1 = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)\n",
        "contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr_fsz1auvLK"
      },
      "source": [
        "def biggestRectangle(contours):\n",
        "    biggest = None\n",
        "    max_area = 0\n",
        "    indexReturn = -1\n",
        "    for index in range(len(contours)):\n",
        "        i = contours[index]\n",
        "        area = cv2.contourArea(i)\n",
        "        if area > 100:\n",
        "            peri = cv2.arcLength(i, True)\n",
        "            approx = cv2.approxPolyDP(i, 0.1 * peri, True)\n",
        "            if area > max_area:  # and len(approx)==4:\n",
        "                biggest = approx\n",
        "                max_area = area\n",
        "                indexReturn = index\n",
        "    return indexReturn\n",
        "\n",
        "\n",
        "indexReturn = biggestRectangle(contours)\n",
        "hull = cv2.convexHull(contours[indexReturn])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvAIlYrruzEC"
      },
      "source": [
        "# create a crop mask\n",
        "mask = np.zeros_like(img)  # Create mask where white is what we want, black otherwise\n",
        "cv2.drawContours(mask, contours, indexReturn, 255, -1)  # Draw filled contour in mask\n",
        "out = np.zeros_like(img)  # Extract out the object and place into output image\n",
        "out[mask == 255] = img[mask == 255]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ei04LiXu3AR",
        "outputId": "a568b3f3-8493-4ddb-a1e4-8b11b40958e2"
      },
      "source": [
        "# crop the image\n",
        "(y, x, _) = np.where(mask == 255)\n",
        "(topy, topx) = (np.min(y), np.min(x))\n",
        "(bottomy, bottomx) = (np.max(y), np.max(x))\n",
        "out = img[topy : bottomy + 1, topx : bottomx + 1, :]\n",
        "cv2.imwrite('3 cropped_img.jpg',out)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpjXASMtu7W5",
        "outputId": "3b1dd4e3-64fd-4c1a-aab9-7fd0f6a6fee2"
      },
      "source": [
        "reader = easyocr.Reader(['en'])\n",
        "image = cv2.imread(\"/content/3 cropped_img.jpg\")\n",
        "output = reader.readtext(image)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULV4Yo6gvJxy"
      },
      "source": [
        "# We point OpenCV's CascadeClassifier function to where our \n",
        "# classifier (XML file format) is stored\n",
        "face_classifier = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZOtsjE9vLX4"
      },
      "source": [
        "# Our classifier returns the ROI of the detected face as a tuple\n",
        "# It stores the top left coordinate and the bottom right coordiantes\n",
        "faces = face_classifier.detectMultiScale(gray, 1.3, 5)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr_PsngEvMIC"
      },
      "source": [
        "# When no faces detected, face_classifier returns and empty tuple\n",
        "if faces is ():\n",
        "    print(\"No faces found\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2mP9I8xvN2k"
      },
      "source": [
        "# We iterate through our faces array and draw a rectangle\n",
        "# over each face in faces\n",
        "for (x, y, w, h) in faces:\n",
        "    x = x - 25 # Padding trick to take the whole face not just Haarcascades points\n",
        "    y = y - 40 # Same here...\n",
        "    cv2.rectangle(image, (x, y), (x + w + 50, y + h + 70), (27, 200, 10), 2)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "for (x, y, width, height) in faces:\n",
        "    roi = image[y:y+height, x:x+width]\n",
        "    cv2.imwrite(\"4 Face_crop.jpg\", roi) # Saving the extracted face photo"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "x7mSv05lvnJr",
        "outputId": "f3e9ddeb-226e-4207-baf7-46735ad88de0"
      },
      "source": [
        "# Extracting and printing out the details from the ID card\n",
        "print(\"Unique ID:\",output[3][1])\n",
        "print(\"=====================\")\n",
        "print(\"Name:\",output[4][1])\n",
        "print(\"=====================\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-37a9c7c0fafa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extracting and printing out the details from the ID card\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique ID:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39GvTIvOvvN6"
      },
      "source": [
        "# Saving the extracted details to a CSV file\n",
        "with open('Database.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Serial No.\", \"Name\", \"Unique ID\"])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEBSfIS5v0Z6"
      },
      "source": [
        "with open('Database.csv', 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([1, output[4][1], output[3][1]])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GflzYspmv3Dz"
      },
      "source": [
        "# Using SpaCy for named entity recognition    \n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULeKGXpgv5nf",
        "outputId": "ae35add7-941c-46f3-a85c-b3baa15bc0bc"
      },
      "source": [
        "output = ''.join(map(str, output))\n",
        "sent = nlp('Aniruddha Mulay')\n",
        "print([token for token in sent if token.ent_type_ == 'PERSON'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    }
  ]
}